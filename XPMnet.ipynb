{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XPMnet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdnzhdiCZS73FGpl1y23n6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9qFY54kdwdc5"},"source":["# REMOVAL OF CROSS-PHASE-MODULATION ARTIFACTS IN ULTRAFAST PUMP-PROBE DYNAMICS VIA DEEP LEARNING\n","\n","# GENERATION OF THE XPMnet TRAINING/VALIDATION DATASET\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","\n","# XPMnet processes single wavelength time dynamics.\n","# XPM starting time t0(lambda) is varied in a typical experimental range:\n","t0 = np.random.uniform(150, 700) #[fs]\n","# Number of time points in the simulated dynamics:\n","t_points = 200 \n","\n","def f_cos(t0):\n","    \"\"\" Input = delay t0\n","        Output = cross-phase modulation (XPM) pattern\n","        time points = t_points\n","        The function simulates randomly reversed peaks (a[0], a[1]), \n","        a random tau, a random phase phi and a random b parameter. \"\"\"\n","    t = np.arange(0, t_points)*5\n","    t0xpm = t0 + round(np.random.uniform(-15, +15))\n","    # Load the 'Experimental_XPM_data provided to perform data augmentation on\n","    # experimentally measured XPM artifacts on soda-lime glass\n","    exp_xpm_data = np.loadtxt(\"/content/gdrive/MyDrive/Colab Notebooks/Experimental_XPM_data.txt\")\n","    dim = exp_xpm_data.shape\n","    select = round(np.random.uniform(0,dim[0]-1))\n","    parameters = exp_xpm_data[select,:]\n","    parameters[0] = parameters[0] + np.random.uniform(-.05, .05)*parameters[0]    \n","    parameters[1] = parameters[1] + np.random.uniform(-.05, .05)*parameters[1]\n","    parameters[2] = parameters[2] + np.random.uniform(-.05, .05)*parameters[2]\n","    parameters[3] = parameters[3] + np.random.uniform(-.05, .05)*parameters[3]\n","    parameters[4] = parameters[4] + np.random.uniform(-.05, .05)*parameters[4]\n","    out = np.cos(parameters[3]*(t-t0xpm)**2+parameters[4])*(parameters[0]* \\\n","          np.exp(-(4*np.log(2)*(t-t0xpm)**2)/parameters[2]**2)-parameters[1]* \\\n","          8*np.log(2)/(parameters[2])**2*(t-t0xpm)*np.exp(-(4*np.log(2)* \\\n","          (t-t0xpm)**2)/parameters[2]**2))\n","    return out\n","\n","def dyn(t0):\n","    \"\"\" Input = delay t0\n","        Output = exponential dynamic pattern\n","        time points = t_points\n","        The function simulates an exponential electronic relaxation dynamic.\n","        Parameters are chose in typical experimental ranges. The set of \n","        parameters comprises: amplitude a, time constant tau and c to account\n","        for the remaining signal after relaxation. \n","        The Heaviside(t0) function is employed. \"\"\"\n","    t = np.arange(0,t_points)\n","    a = np.random.uniform(.0017, .013)\n","    tau = np.random.uniform(150, 300)\n","    c = np.random.uniform(0, 1E-5)\n","    h=np.zeros(t_points)\n","    h[round(t0/5):t_points] = 1\n","    out = (-a*np.exp(-(t*5-t0)/tau)+c)*h\n","    return out\n"," \n","def f_sech():\n","    \"\"\" Output = pulse pattern as an hyperbolic secant (sech)\n","        The function simulates a pulse pattern with a FWHM in typical\n","        experimental ranges \"\"\"\n","    t2 = int(t_points/2)\n","    fwhm = np.random.uniform(16, 26)\n","    sigma0=fwhm/1.76\n","    X = sigma0/(2*np.log(2+math.sqrt(3)))\n","    hyper_secant = np.zeros(t_points)\n","    for i in range(-t2, t2):\n","        hyper_secant[i] = ((2/(np.exp(i/X) + np.exp(-i/X))))\n","    out = np.zeros(t_points)\n","    out[0:t2] = hyper_secant[t2:t_points]\n","    out[t2:t_points] = hyper_secant[0:t2]\n","    out=out**2\n","    out=out/np.trapz(out)\n","    \n","    return out\n","\n","def generate_dynamics():\n","    \"\"\" Output: INPUT X of the XPMnet , OUTPUT Y of the XPMnet, \n","        exponential dynamics, pulse dynamics, XPM dynamics, \n","        convolution(exponential dynamics, pulse dynamics).\n","        The function normalizes the X and Y in the range [0, 1]. \"\"\"\n","    t0 = np.random.uniform(150, 700)\n","    # Creation of X and Y  \n","    d = dyn(t0)\n","    s = f_sech()\n","    f = f_cos(t0)\n","    c = np.convolve(d, s, mode='same')\n","    noise = np.random.randn(t_points)*np.random.uniform(.00003, .0001)\n","    # Input X\n","    X = c + f + noise\n","    # Output Y\n","    Y = c\n","    # Normalization of X and Y\n","    X_norm =(X +0.02)/(0.0063 + 0.02)\n","    Y_norm =(Y +0.02)/(0.0063 + 0.02)\n","    return X_norm, Y_norm, d, s, f, c\n","\n","def data_augmentation(X, y, n_augmented):\n","    \"\"\" Input: Training/validation dataset to augment \n","        (input X and ground truth y) and the desired number of augmented \n","        instances to generate.\n","        Output: augmented X and augmented ground truth y\n","        This function aims at augmenting the dataset to account for a varying \n","        baseline in the input data points, due to a case-specific\n","        normalization. \"\"\"\n","    augmented = 0\n","    batch_dim = X.shape[0]\n","    print(batch_dim)\n","    augmented_instance_X = np.empty((batch_dim + n_augmented, t_points, 1))\n","    augmented_instance_y = np.empty((batch_dim + n_augmented, t_points))\n","    for i in range(batch_dim):\n","        augmented_instance_X[i, :, 0] = X[i, :, 0].flatten()\n","        augmented_instance_y[i, :] = y[i, :].flatten()\n","    while augmented < n_augmented:\n","        Xnew, Ynew, d, s, f, c = generate_dynamics()\n","        if np.min(Xnew) > .3:\n","            baseline_shift = np.random.uniform(0, .3)\n","            Xnew = Xnew - baseline_shift\n","            Ynew = Ynew - baseline_shift\n","            augmented_instance_X[batch_dim + augmented,:, 0] = Xnew \n","            augmented_instance_y[batch_dim + augmented, :] = Ynew\n","            augmented += 1\n","    print(f\"Dataset successfully augmented by {augmented} instances.\")\n","    return augmented_instance_X, augmented_instance_y\n","   \n","X_norm, Y_norm, d, s, f, c = generate_dynamics()\n","\n","# Plotting:\n","print('Example of generated train/test instance:')\n","t = np.arange(0, t_points)*5\n","fig, axs = plt.subplots(3, 2, sharex=True)\n","plt.subplots_adjust(hspace = .5, wspace = .5)\n","axs[0, 0].plot(t, f)\n","axs[0, 0].set_title(\"XPM artifact\")\n","axs[1, 0].plot(t, d)\n","axs[1, 0].set_title(\"Exponential dynamic\")\n","axs[0, 1].plot(t, s)\n","axs[0, 1].set_title(\"Pump pulse\")\n","axs[1, 1].plot(t, c)\n","axs[1, 1].set_title(\"Electron cooling dynamics\")\n","axs[2, 0].plot(t, X_norm)\n","axs[2, 0].set_ylim([0, 1])\n","axs[2, 0].set_title(\"XPMnet input\")\n","axs[2, 1].plot(t, Y_norm)\n","axs[2, 1].set_title(\"XPMnet ground truth\")\n","axs[2, 1].set_ylim([0, 1])\n","np.savetxt(\"plotxpm\", f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIztd5lo0Lb_"},"source":["# BUILD, COMPILE AND FIT XPMnet\n","#from xpmnet_short_1 import generate_dynamics, data_augmentation\n","import numpy as np\n","import tensorflow as tf\n","import time\n","\n","tf.keras.backend.clear_session()\n","#Number of time points in the simulated dynamics:\n","t_points = 200 \n","\n","def generate_batch(n=1):\n","    \"\"\" Input = number of desired simulated dynamics to train and\n","        validate XPMnet\n","        Output = XPMnet input X, XPMnet output y \"\"\"\n","    X = np.empty((n, t_points, 1))\n","    y = np.empty((n, t_points))\n","    for i in range(n):\n","        X[i,:, 0], y[i, :], d, s, f, c = generate_dynamics()\n","    return X, y\n","\n","def R_squared(y_true, y_pred):\n","    \"\"\" Computes the Rsquared coefficient, index of the accuracy\n","        of prediction in regression-like problems. This coefficient will be\n","        used as a metric during the XPMnet training/validation \"\"\"\n","    SS_res =  tf.keras.backend.sum(tf.keras.backend.square(y_true-y_pred)) \n","    SS_tot = tf.keras.backend.sum(tf.keras.backend.square(y_true-tf.keras.backend.mean(y_true))) \n","    return (1-SS_res/(SS_tot+tf.keras.backend.epsilon()))\n","\n","def plot_metric(history, metric, yscale):\n","    \"\"\" Plots the metrics per training/validation epoch.\n","        Input: history of the model, metric to plot and y-axis scale ('log' for\n","        logarithmic scale, 'linear' for linear scale)\"\"\"\n","    train_metrics = history.history[metric]\n","    val_metrics = history.history['val_'+metric]\n","    start_epoch = 1\n","    epochs = range(start_epoch, len(train_metrics) + 1)\n","    plt.figure()\n","    plt.subplot(121)\n","    plt.grid(True)\n","    plt.yscale(yscale)\n","    plt.plot(epochs, train_metrics, epochs, val_metrics)\n","    plt.ylim(0, 1)\n","    plt.xticks(np.arange(start_epoch, len(train_metrics) + 1, 1.0))\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(metric)\n","    plt.title('Training and validation '+ metric)\n","    plt.legend([\"train_\"+metric, 'val_'+ metric])    \n","\n","# Generate the XPMnet training/validation batch\n","start = time.time()\n","print('Generating the XPMnet train/test dataset...')\n","X, y = generate_batch(40000)\n","# Perform data augmentation to compensate for baseline shifting\n","start1 = time.time()\n","X_augmented, y_augmented = data_augmentation(X, y, 40000)\n","end = time.time()\n","print('...XPMnet train/test dataset successfully generated!')\n","print(\"Dataset generation time: {:.2f} min\".format((end - start)/60))\n","\n","# Build XPMnet\n","model = tf.keras.Sequential([\n","\n","    tf.keras.layers.BatchNormalization(input_shape=(t_points, 1)),\n","    \n","    tf.keras.layers.Conv1D(128, 32, activation='relu'),\n","    \n","    tf.keras.layers.Conv1D(96, 24, activation='relu'),\n","\n","    tf.keras.layers.Conv1D(64, 8, activation='relu'),\n","    tf.keras.layers.Conv1D(8, 3, activation='relu'),\n","    tf.keras.layers.Conv1D(8, 3, activation='relu'),\n","    tf.keras.layers.Conv1D(8, 3, activation='relu'),\n","    \n","    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0,l2=0.1)),\n","    tf.keras.layers.Dense(36, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0,l2=0.1)),\n","    tf.keras.layers.Dense(36, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0,l2=0.1)),\n","   \n","    \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(.35),\n","    tf.keras.layers.Dense(t_points, activation='relu')\n","    \n","    ])\n","\n","model.compile(loss='mean_absolute_percentage_error', optimizer='Adam', metrics=['mean_squared_error', 'mean_absolute_percentage_error', R_squared])\n","print(model.summary())\n","\n","history = model.fit(X_augmented, y_augmented, epochs=100, verbose=1, validation_split=0.25, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3ENtqAS3gsp"},"source":["# PLOT THE TRAINING & VALIDATION HISTORY\n","import matplotlib.pyplot as plt\n","\n","metric = 'loss'\n","yscale = 'linear'\n","train_metrics = history.history[metric]\n","val_metrics = history.history['val_'+metric]\n","start_epoch = 1\n","epochs = range(start_epoch, len(train_metrics) + 1)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121)\n","plt.grid(True)\n","plt.yscale(yscale)\n","plt.plot(epochs, train_metrics, epochs, val_metrics)\n","plt.xticks(np.arange(start_epoch, len(train_metrics) + 1, 1.0))\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(metric)\n","plt.title('Training and validation '+ metric)\n","plt.legend([\"train_\"+metric, 'val_'+ metric]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnPtxclZ0-Dw"},"source":["# TEST THE CNN PREDICTION ON INDIVIDUAL RANDOMLY GENERATED ISTANCES\n","import time\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","X, y_true = generate_batch(1)\n","start = time.time()\n","y_pred = model.predict([X])\n","end = time.time()\n","print(\"XPM artifact removal time: {:.2f} s\".format(end - start))\n","t = np.arange(0, t_points)*5\n","plt.plot(t, X.flatten(), t, y_true.T, t, y_pred.flatten())\n","plt.legend([\"Simulated XPM-affected dynamic\", \"Ground truth\", \"XPMnet retrieved dynamics\"])\n","plt.xlabel(\"Time [fs]\")\n","plt.ylabel(\"Normalized intensity\")\n","plt.ylim(0, 1)"],"execution_count":null,"outputs":[]}]}